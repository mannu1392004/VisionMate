# VisionMate ‚Äî Smart Navigation for the Visually Impaired

> A real-time object detection and navigation assistant for visually impaired users, built with Android, ML Kit, Firebase, and CameraX.

---

## ü¶æ About the Project

**VisionMate** is an Android-based smart navigation assistant designed to empower visually impaired users by helping them navigate the world safely and independently. Using on-device AI object detection, voice-guided navigation, and real-time alerts, GuideAI offers enhanced environmental awareness for users ‚Äî turning a smartphone into a digital companion.

---

## üöÄ Features

- üéØ **Real-Time Object Detection**  
  Uses Firebase ML Kit + CameraX to detect and describe obstacles and surroundings.

- üó∫Ô∏è **Voice Navigation Support**  
  Turn-by-turn audio navigation using GPS and Google Maps API.

- üîä **Audio Feedback**  
  Real-time voice alerts like:  
  > ‚ÄúStairs ahead.‚Äù  
  > ‚ÄúPerson 3 meters away on your right.‚Äù

- üß† **Offline Detection Support**  
  On-device inference for object detection using ML Kit ‚Äî even without an internet connection.

- üó£Ô∏è **Voice Commands**  
  Users can interact hands-free via speech (e.g. start/stop navigation, SOS mode).

- ‚ö° **Emergency SOS Mode**  
  Send live location and emergency messages to caregivers with a single voice command or button press.

---

## üõ†Ô∏è Tech Stack

| Tech                | Purpose                         |
|---------------------|---------------------------------|
| Android (Jetpack Compose) | UI & app architecture            |
| Firebase ML Kit     | Object Detection (on-device & cloud) |
| CameraX             | Real-time camera feed management |
| Google Maps API     | Navigation & location services   |
| Text-to-Speech (TTS)| Voice alerts                    |
| Speech Recognition  | Voice command input             |
| Firebase Realtime DB / Firestore | (Optional) User data, history, preferences |

---

## üí° How it Works

1. **CameraX** streams the live feed from the device camera.
2. **Firebase ML Kit** detects and classifies objects in real-time.
3. Detected objects are described via **Text-to-Speech (TTS)** for the user.
4. **Google Maps API** provides walking directions with audio instructions.
5. **Voice Commands** allow users to control the app hands-free.
6. **SOS Mode** can alert emergency contacts with GPS location and surroundings snapshot.

---

## ‚ö†Ô∏è Disclaimer

This app is designed to **assist** and support visually impaired users, but it is not a substitute for caution or human supervision in high-risk environments. Always use with awareness of your surroundings.

---

## ü§ù Contributing

Contributions are welcome!  
If you'd like to improve GuideAI or report issues, please open a Pull Request or submit an Issue.

---


## üì¢ Credits
Special thanks to Firebase, Google Maps API, and the open-source Android community.

---

